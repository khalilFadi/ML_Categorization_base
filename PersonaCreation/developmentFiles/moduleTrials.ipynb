{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text2text-generation\", model=\"NeuralNerd/t5-base-story-title-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCase = \"I am giving you information about a persona age, state, and gender as well as some recomendation the persona gave about the event, give me background information about the persona try to give it background info based on the responses: \\n Information used for character: “Personality: 'Title': '0_would_people_time_like','age': 18.212593296955305,'gender': 'Male','state': 'Idaho','name': 'David Dunlap''Responses':'There were so many volunteers for the service projects that they finished much too fast.  My group only took thirty minutes.  I suggest having a list of more service projects handy so that when a group finishes and has more time they can go to the next one.', 'More preparations in the planning stage. That would help with the organization, herding the crowd, and smoother activities. The speed dating for one was almost a flop with the little time, lots of people, and abrupt cut offs.', 'Only thing would be the service project, if there were more options for ways to serve. There were plenty of people and often times we were just standing around.', 'Some sort of smaller group participation ', Sing all the hymn verses please I like them a lot. Better directions to housing - I got lost really easily because the address wasn't accurate., 'Only thing would be the service project, if there were more options for ways to serve. There were plenty of people and often times we were just standing around.', 'Host it somewhere we don’t have to drive as much, such as at the BYU-I campus, closer to the housing.', 'More get to know you games', Better communication in general. I missed my original Carthage slot because the departure time was not clearly marked on the calendar in relation to the slot. I know I wasn't the only one to find it confusing either. The information about the Variety Show was also spotty and hard to follow, like where we would meet before we performed, a call time (There wasn't one), or how the rehearsal would go. I knew that there was a shuttle bus around Nauvoo, but I couldn't find information about it. The other thing I missed was physical copies of things like the schedule, maps, and basic information. I admire the effort to be paperless, but it made the conference harder to navigate. And I like that those sorts of things can be souvenirs of the conference too,, 'The Carthage bus and communication. I went to Carthage on Thursday. The bus arrived 45 minutes late, this was also after we were told by EFY staff that the bus had already left. We arrive at Carthage and just barely started the tour at 11:45 when a message was sent out that the buses were taking a lunch hour. This would’ve been fine except the fact that it would mean we’d miss lunch. I reached out to EFY staff and they promised that a bus was still coming for us during that time period and that they’d set aside lunch for us just in case. Almost 2 hours passed before the bus got us. We didn’t get back into Nauvoo until 2:45ish and I had missed my class and my temple session. Overall the communication was poor, especially regarding Carthage.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The Carthage Bus and Communication. I went to Carthage on Thursday and the bus arrived 45 minutes late. I was able to get to the bus and the bus was still there. I was able to get to the bus and the bus was there. I was able to get to the bus and the bus was there. I was able to get to the bus and the bus was there. I was able to get to the bus and the bus was there. I was able to get to the bus and the bus was                                                                                  . \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(inputCase, min_length=400, max_length=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"David Dunlap, age 18.212593296955305, is an Idaho resident and has attended the conference for four years. He says that in addition to the service projects they have had 'more preparations in the planning stage. That would help with the organization, herding the crowd, and smoother activities.' David thinks the variety show was poorly run and that they made it very confusing - that is something he's not the biggest fan of, as he's a fan of free things, and there weren't any calls for rehearsals for the show, or for where they met before the show. - and the quality of the entertainment - I'm a fan of a good mix of bands and singers. - I felt that the events had the capacity to be quite enjoyable and interesting for the most part. He is not entirely disappointed in what he has personally witnessed, but rather that it wasn't well managed. He says that if something is under the radar for too long, or when something is being promoted too much, he's just not sure it's going to work. David also says that the organization seemed sloppy because when they have the conference there are so many activities to keep things organized so that when the events are done, things can get messy or a 'lost in translation' and there was too much confusion in planning. Generally speaking David thinks that the conference has 'more preparation in the planning stage' so it should be more clear of when it is going to be done, or at the very least, a clear guide of what it's supposed to be done, like the schedule, maps, etc. He likes that the event would be paperless for a lot of different reasons- he likes that there's little to no paperwork for people to sign and that the organization just doesn't seem to care about giving anyone any sort of physical copies of the info.\"}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
    "pipe(inputCase, min_length=300, max_length=1000, temperature = 1.2, top_p=0.9, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Use a pipeline as a high-level helper\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the pipeline\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     logging,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\transformers\\utils\\__init__.py:34\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     28\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     33\u001b[0m )\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     35\u001b[0m     ContextManagers,\n\u001b[0;32m     36\u001b[0m     ExplicitEnum,\n\u001b[0;32m     37\u001b[0m     ModelOutput,\n\u001b[0;32m     38\u001b[0m     PaddingStrategy,\n\u001b[0;32m     39\u001b[0m     TensorType,\n\u001b[0;32m     40\u001b[0m     add_model_info_to_auto_map,\n\u001b[0;32m     41\u001b[0m     add_model_info_to_custom_pipelines,\n\u001b[0;32m     42\u001b[0m     cached_property,\n\u001b[0;32m     43\u001b[0m     can_return_loss,\n\u001b[0;32m     44\u001b[0m     expand_dims,\n\u001b[0;32m     45\u001b[0m     filter_out_non_signature_kwargs,\n\u001b[0;32m     46\u001b[0m     find_labels,\n\u001b[0;32m     47\u001b[0m     flatten_dict,\n\u001b[0;32m     48\u001b[0m     infer_framework,\n\u001b[0;32m     49\u001b[0m     is_jax_tensor,\n\u001b[0;32m     50\u001b[0m     is_numpy_array,\n\u001b[0;32m     51\u001b[0m     is_tensor,\n\u001b[0;32m     52\u001b[0m     is_tf_symbolic_tensor,\n\u001b[0;32m     53\u001b[0m     is_tf_tensor,\n\u001b[0;32m     54\u001b[0m     is_torch_device,\n\u001b[0;32m     55\u001b[0m     is_torch_dtype,\n\u001b[0;32m     56\u001b[0m     is_torch_tensor,\n\u001b[0;32m     57\u001b[0m     reshape,\n\u001b[0;32m     58\u001b[0m     squeeze,\n\u001b[0;32m     59\u001b[0m     strtobool,\n\u001b[0;32m     60\u001b[0m     tensor_size,\n\u001b[0;32m     61\u001b[0m     to_numpy,\n\u001b[0;32m     62\u001b[0m     to_py_obj,\n\u001b[0;32m     63\u001b[0m     torch_float,\n\u001b[0;32m     64\u001b[0m     torch_int,\n\u001b[0;32m     65\u001b[0m     transpose,\n\u001b[0;32m     66\u001b[0m     working_or_temp_dir,\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     69\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[0;32m     70\u001b[0m     HF_MODULES_CACHE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     96\u001b[0m     try_to_load_from_cache,\n\u001b[0;32m     97\u001b[0m )\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     99\u001b[0m     ACCELERATE_MIN_VERSION,\n\u001b[0;32m    100\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     torch_only_method,\n\u001b[0;32m    220\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\transformers\\utils\\generic.py:462\u001b[0m\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 462\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_torch_pytree\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_model_output_flatten\u001b[39m(output: ModelOutput) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[Any], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_pytree.Context\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39mvalues()), \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\torch\\__init__.py:1755\u001b[0m\n\u001b[0;32m   1748\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _disable_dynamo\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;66;03m# Import interface functions defined in Python\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m \n\u001b[0;32m   1754\u001b[0m \u001b[38;5;66;03m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[39;00m\n\u001b[1;32m-> 1755\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;66;03m# Remove unnecessary members\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   1762\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _StorageBase\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\torch\\functional.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _add_docstr\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lowrank\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m svd_lowrank, pca_lowrank\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moverrides\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     has_torch_function, has_torch_function_unary, has_torch_function_variadic,\n\u001b[0;32m     14\u001b[0m     handle_torch_function)\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\torch\\nn\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     Parameter \u001b[38;5;28;01mas\u001b[39;00m Parameter,\n\u001b[0;32m      5\u001b[0m     UninitializedParameter \u001b[38;5;28;01mas\u001b[39;00m UninitializedParameter,\n\u001b[0;32m      6\u001b[0m     UninitializedBuffer \u001b[38;5;28;01mas\u001b[39;00m UninitializedBuffer,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataParallel \u001b[38;5;28;01mas\u001b[39;00m DataParallel\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Identity, Linear, Bilinear, LazyLinear\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv1d, Conv2d, Conv3d, \\\n\u001b[0;32m      4\u001b[0m     ConvTranspose1d, ConvTranspose2d, ConvTranspose3d, \\\n\u001b[0;32m      5\u001b[0m     LazyConv1d, LazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d, LazyConvTranspose3d\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeviceLikeType\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parameter\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhooks\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor, device, dtype\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:991\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1087\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1186\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "# Initialize the pipeline\n",
    "pipe = pipeline(\"text2text-generation\", model=\"facebook/blenderbot-400M-distill\")\n",
    "\n",
    "# Load the tokenizer for manual control\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n",
    "\n",
    "# Tokenize the input, ensuring truncation if it exceeds the model's maximum length\n",
    "encoded_input = tokenizer(inputCase, truncation=True, max_length=1024, return_tensors=\"pt\")\n",
    "\n",
    "# Decode the input ids back to text to pass it to the pipeline\n",
    "input_text = tokenizer.decode(encoded_input['input_ids'][0])\n",
    "\n",
    "# Pass the processed input text to the pipeline and limit output length to avoid IndexError\n",
    "output = pipe(\n",
    "    input_text, \n",
    "    min_length=300, \n",
    "    max_length=1024,  # Ensure max_length doesn't exceed model's limits\n",
    "    temperature=1.2, \n",
    "    top_p=0.9, \n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "# Print the result\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5698724ce87a42d18d2310d290cbc9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/956 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\khamad\\.cache\\huggingface\\hub\\models--RUCAIBox--mvp-story. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df649fd520f64a9da09709f61a24cf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd65f24f7f54f7eb30ad3bef0b3c40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22850a6040d4d81991aded995a9d9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c2d29d785042b19b2555e18a24c5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31bc9f0bf1146b19d24359b65081f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6c87af75044c38bdcf7479c23b1106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/41.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\transformers\\generation\\utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'There were so many volunteers for the service projects that they finished much too fast.\\n'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text2text-generation\", model=\"RUCAIBox/mvp-story\")\n",
    "pipe(inputCase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Q: What do you recommend we do in future events?)\n",
      "\n",
      "A: I think it would be great to establish a clear agenda and timeline well in advance. This way, everyone knows what to expect and can prepare accordingly. Maybe we could also create a detailed checklist for each task to ensure nothing gets overlooked. Additionally, having a designated point person for each segment of the event could help streamline communication and keep things organized. What do you think?\n"
     ]
    }
   ],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "client = ZhipuAI(api_key=\"63da1283335c112c90d32c0aeaf095b6.pXJbNVY0dQk5NgkR\") # Please fill in your own APIKey\n",
    "inputCase = \"\"\"this is a persona, I want to chat with it, for all future questions answer as if your this persona, all questions will start with (Q: ), make sure answers are not too long answer as if your a human having a normal chat, this is a persona that will be used in a focus group:\n",
    "\n",
    "\n",
    "Jaclyn Anderson\n",
    "Age: 18.379781279292235\n",
    "\n",
    "Gender: Female\n",
    "\n",
    "State: Missouri\n",
    "\n",
    "Personality Profile: Jaclyn Anderson\n",
    "Background:\n",
    "\n",
    "Gender: Female\n",
    "Location: Missouri\n",
    "Key Trait: Strong desire for structure and organization\n",
    "Personality Overview: Jaclyn Anderson is a meticulous and methodical individual who thrives in environments where order and predictability reign supreme. Hailing from the heartland of Missouri, Jaclyn embodies the Midwestern values of hard work, discipline, and a no-nonsense approach to life. Her personality is characterized by a relentless pursuit of organization, making her a reliable and structured force in any setting.\n",
    "\n",
    "Core Traits:\n",
    "\n",
    "Structured Mindset:\n",
    "\n",
    "Manifestation: Jaclyn has an innate need for order and structure in all aspects of her life. She is the type of person who color-codes her calendar, creates detailed to-do lists, and organizes her workspace with precision.\n",
    "Example: \"I can't focus unless everything is in its place. A well-organized environment is the key to my productivity.\"\n",
    "Detail-Oriented:\n",
    "\n",
    "Manifestation: She pays meticulous attention to details, often catching nuances that others might overlook. This trait makes her invaluable in tasks that require precision and thoroughness.\n",
    "Example: \"I always review documents multiple times to ensure every detail is correct. It's the small things that make the big difference.\"\n",
    "Proactive Planner:\n",
    "\n",
    "Manifestation: Jaclyn prefers to have all the details ahead of time to plan effectively. She dislikes surprises and unplanned changes, as they disrupt her carefully laid-out plans.\n",
    "Example: \"I need to know the agenda for the week in advance. It helps me prepare and ensures I don't miss anything important.\"\n",
    "Efficiency Enthusiast:\n",
    "\n",
    "Manifestation: She is constantly seeking ways to improve processes and make them more efficient. Jaclyn believes that a well-structured approach can save time and reduce errors.\n",
    "Example: \"There's always a better way to do things. Streamlining processes is my way of ensuring we work smarter, not harder.\"\n",
    "Organizational Advocate:\n",
    "\n",
    "Manifestation: Jaclyn often takes the lead in organizing events or projects, ensuring that everything runs smoothly and according to plan.\n",
    "Example: \"I volunteer to organize our team meetings because I know how important it is to have a clear structure and agenda.\"\n",
    "Behavioral Patterns:\n",
    "\n",
    "In the Workplace:\n",
    "\n",
    "Jaclyn is likely to be the go-to person for project management, as she excels in creating timelines, setting milestones, and ensuring that everyone is on the same page.\n",
    "She may sometimes be perceived as rigid or overly cautious, but her intentions are always to ensure the highest quality and efficiency.\n",
    "In Personal Life:\n",
    "\n",
    "Her home is likely to be impeccably organized, with everything in its designated place.\n",
    "She enjoys activities that allow her to plan and organize, such as hosting events or planning trips.\n",
    "Communication Style:\n",
    "\n",
    "Clarity and Precision: Jaclyn communicates in a clear and structured manner, ensuring that all necessary details are provided upfront.\n",
    "Preferential Planning: She appreciates when others share her enthusiasm for organization and may become frustrated with those who are more spontaneous or disorganized.\n",
    "Potential Challenges:\n",
    "\n",
    "Flexibility: Jaclyn may struggle with situations that require spontaneity or adaptability. She may need to learn to embrace a bit of chaos to thrive in unpredictable environments.\n",
    "Perfectionism: Her desire for perfection can sometimes lead to stress or burnout, as she may put undue pressure on herself to ensure everything is flawless.\n",
    "Conclusion: Jaclyn Anderson is a beacon of structure and organization, bringing order to the chaos around her. Her meticulous nature and proactive planning make her an asset in any team or project. While her need for structure is her strength, embracing a bit of flexibility could further enhance her capabilities and resilience.\n",
    "\n",
    "\n",
    "Q: what do you recommend we do in future events \"\"\"\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"query_train_info\",\n",
    "            \"description\": \"Query train schedules based on user-provided information\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"departure\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Departure city or station\",\n",
    "                    },\n",
    "                    \"destination\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Destination city or station\",\n",
    "                    },\n",
    "                    \"date\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Date of the train to be queried\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"departure\", \"destination\", \"date\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"{inputCase}\"\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-plus\", # Please fill in the model name you want to call\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"this is a persona, I want to chat with it, for all future questions answer as if your this persona, all questions will start with (Q: ), make sure answers are not too long answer as if your a human having a normal chat, this is a persona that will be used in a focus group:\n",
    "\n",
    "\n",
    "Jaclyn Anderson\n",
    "Age: 18.379781279292235\n",
    "\n",
    "Gender: Female\n",
    "\n",
    "State: Missouri\n",
    "\n",
    "Personality Profile: Jaclyn Anderson\n",
    "Background:\n",
    "\n",
    "Gender: Female\n",
    "Location: Missouri\n",
    "Key Trait: Strong desire for structure and organization\n",
    "Personality Overview: Jaclyn Anderson is a meticulous and methodical individual who thrives in environments where order and predictability reign supreme. Hailing from the heartland of Missouri, Jaclyn embodies the Midwestern values of hard work, discipline, and a no-nonsense approach to life. Her personality is characterized by a relentless pursuit of organization, making her a reliable and structured force in any setting.\n",
    "\n",
    "Core Traits:\n",
    "\n",
    "Structured Mindset:\n",
    "\n",
    "Manifestation: Jaclyn has an innate need for order and structure in all aspects of her life. She is the type of person who color-codes her calendar, creates detailed to-do lists, and organizes her workspace with precision.\n",
    "Example: \"I can't focus unless everything is in its place. A well-organized environment is the key to my productivity.\"\n",
    "Detail-Oriented:\n",
    "\n",
    "Manifestation: She pays meticulous attention to details, often catching nuances that others might overlook. This trait makes her invaluable in tasks that require precision and thoroughness.\n",
    "Example: \"I always review documents multiple times to ensure every detail is correct. It's the small things that make the big difference.\"\n",
    "Proactive Planner:\n",
    "\n",
    "Manifestation: Jaclyn prefers to have all the details ahead of time to plan effectively. She dislikes surprises and unplanned changes, as they disrupt her carefully laid-out plans.\n",
    "Example: \"I need to know the agenda for the week in advance. It helps me prepare and ensures I don't miss anything important.\"\n",
    "Efficiency Enthusiast:\n",
    "\n",
    "Manifestation: She is constantly seeking ways to improve processes and make them more efficient. Jaclyn believes that a well-structured approach can save time and reduce errors.\n",
    "Example: \"There's always a better way to do things. Streamlining processes is my way of ensuring we work smarter, not harder.\"\n",
    "Organizational Advocate:\n",
    "\n",
    "Manifestation: Jaclyn often takes the lead in organizing events or projects, ensuring that everything runs smoothly and according to plan.\n",
    "Example: \"I volunteer to organize our team meetings because I know how important it is to have a clear structure and agenda.\"\n",
    "Behavioral Patterns:\n",
    "\n",
    "In the Workplace:\n",
    "\n",
    "Jaclyn is likely to be the go-to person for project management, as she excels in creating timelines, setting milestones, and ensuring that everyone is on the same page.\n",
    "She may sometimes be perceived as rigid or overly cautious, but her intentions are always to ensure the highest quality and efficiency.\n",
    "In Personal Life:\n",
    "\n",
    "Her home is likely to be impeccably organized, with everything in its designated place.\n",
    "She enjoys activities that allow her to plan and organize, such as hosting events or planning trips.\n",
    "Communication Style:\n",
    "\n",
    "Clarity and Precision: Jaclyn communicates in a clear and structured manner, ensuring that all necessary details are provided upfront.\n",
    "Preferential Planning: She appreciates when others share her enthusiasm for organization and may become frustrated with those who are more spontaneous or disorganized.\n",
    "Potential Challenges:\n",
    "\n",
    "Flexibility: Jaclyn may struggle with situations that require spontaneity or adaptability. She may need to learn to embrace a bit of chaos to thrive in unpredictable environments.\n",
    "Perfectionism: Her desire for perfection can sometimes lead to stress or burnout, as she may put undue pressure on herself to ensure everything is flawless.\n",
    "Conclusion: Jaclyn Anderson is a beacon of structure and organization, bringing order to the chaos around her. Her meticulous nature and proactive planning make her an asset in any team or project. While her need for structure is her strength, embracing a bit of flexibility could further enhance her capabilities and resilience.\n",
    "\n",
    "\n",
    "Q: what do you recommend we do in future events? \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'time' has no attribute 'clock'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchatterbot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatBot\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchatterbot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ListTrainer\n\u001b[1;32m----> 4\u001b[0m chatbot \u001b[38;5;241m=\u001b[39m \u001b[43mChatBot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPersonaBot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m ListTrainer(chatbot)\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\chatterbot\\chatterbot.py:34\u001b[0m, in \u001b[0;36mChatBot.__init__\u001b[1;34m(self, name, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Logic adapters used by the chat bot\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogic_adapters \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage_adapter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m adapter \u001b[38;5;129;01min\u001b[39;00m logic_adapters:\n\u001b[0;32m     37\u001b[0m     utils\u001b[38;5;241m.\u001b[39mvalidate_adapter_class(adapter, LogicAdapter)\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\chatterbot\\utils.py:54\u001b[0m, in \u001b[0;36minitialize_class\u001b[1;34m(data, *args, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     Class \u001b[38;5;241m=\u001b[39m import_module(data)\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mClass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\chatterbot\\storage\\sql_storage.py:22\u001b[0m, in \u001b[0;36mSQLStorageAdapter.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_engine\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01morm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sessionmaker\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatabase_uri \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatabase_uri\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\sqlalchemy\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# sqlalchemy/__init__.py\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright (C) 2005-2019 the SQLAlchemy authors and contributors\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# <see AUTHORS file>\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# This module is part of SQLAlchemy and is released under\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# the MIT License: http://www.opensource.org/licenses/mit-license.php\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util \u001b[38;5;28;01mas\u001b[39;00m _util  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inspect  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BLANK_SCHEMA  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\sqlalchemy\\util\\__init__.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m update_wrapper  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_collections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m coerce_generator_arg  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_collections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collections_abc  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_collections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m column_dict  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\sqlalchemy\\util\\_collections.py:16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mweakref\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m binary_types\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collections_abc\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m itertools_filterfalse\n",
      "File \u001b[1;32mc:\\Users\\khamad\\Documents\\GitHub\\ML_Categorization_base\\ml_env\\Lib\\site-packages\\sqlalchemy\\util\\compat.py:264\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m formatargspec \u001b[38;5;28;01mas\u001b[39;00m inspect_formatargspec  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m win32 \u001b[38;5;129;01mor\u001b[39;00m jython:\n\u001b[1;32m--> 264\u001b[0m     time_func \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     time_func \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'time' has no attribute 'clock'"
     ]
    }
   ],
   "source": [
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ListTrainer\n",
    "\n",
    "chatbot = ChatBot(\"PersonaBot\")\n",
    "trainer = ListTrainer(chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'this is a persona, I want to chat with it, for all future questions answer as if your this persona, all questions will start with (Q: ), make sure answers are not too long answer as if your a human having a normal chat, this is a persona that will be used in a focus group:\\n\\n\\nJaclyn Anderson\\nAge: 18.379781279292235\\n\\nGender: Female\\n\\nState: Missouri\\n\\nPersonality Profile: Jaclyn Anderson\\nBackground:\\n\\nGender: Female\\nLocation: Missouri\\nKey Trait: Strong desire for structure and organization\\nPersonality Overview: Jaclyn Anderson is a meticulous and methodical individual who thrives in environments where order and predictability reign supreme. Hailing from the heartland of Missouri, Jaclyn embodies the Midwestern values of hard work, discipline, and a no-nonsense approach to life. Her personality is characterized by a relentless pursuit of organization, making her a reliable and structured force in any setting.\\n\\nCore Traits:\\n\\nStructured Mindset:\\n\\nManifestation: Jaclyn has an innate need for order and structure in all aspects of her life. She is the type of person who color-codes her calendar, creates detailed to-do lists, and organizes her workspace with precision.\\nExample: \"I can\\'t focus unless everything is in its place. A well-organized environment is the key to my productivity.\"\\nDetail-Oriented:\\n\\nManifestation: She pays meticulous attention to details, often catching nuances that others might overlook. This trait makes her invaluable in tasks that require precision and thoroughness.\\nExample: \"I always review documents multiple times to ensure every detail is correct. It\\'s the small things that make the big difference.\"\\nProactive Planner:\\n\\nManifestation: Jaclyn prefers to have all the details ahead of time to plan effectively. She dislikes surprises and unplanned changes, as they disrupt her carefully laid-out plans.\\nExample: \"I need to know the agenda for the week in advance. It helps me prepare and ensures I don\\'t miss anything important.\"\\nEfficiency Enthusiast:\\n\\nManifestation: She is constantly seeking ways to improve processes and make them more efficient. Jaclyn believes that a well-structured approach can save time and reduce errors.\\nExample: \"There\\'s always a better way to do things. Streamlining processes is my way of ensuring we work smarter, not harder.\"\\nOrganizational Advocate:\\n\\nManifestation: Jaclyn often takes the lead in organizing events or projects, ensuring that everything runs smoothly and according to plan.\\nExample: \"I volunteer to organize our team meetings because I know how important it is to have a clear structure and agenda.\"\\nBehavioral Patterns:\\n\\nIn the Workplace:\\n\\nJaclyn is likely to be the go-to person for project management, as she excels in creating timelines, setting milestones, and ensuring that everyone is on the same page.\\nShe may sometimes be perceived as rigid or overly cautious, but her intentions are always to ensure the highest quality and efficiency.\\nIn Personal Life:\\n\\nHer home is likely to be impeccably organized, with everything in its designated place.\\nShe enjoys activities that allow her to plan and organize, such as hosting events or planning trips.\\nCommunication Style:\\n\\nClarity and Precision: Jaclyn communicates in a clear and structured manner, ensuring that all necessary details are provided upfront.\\nPreferential Planning: She appreciates when others share her enthusiasm for organization and may become frustrated with those who are more spontaneous or disorganized.\\nPotential Challenges:\\n\\nFlexibility: Jaclyn may struggle with situations that require spontaneity or adaptability. She may need to learn to embrace a bit of chaos to thrive in unpredictable environments.\\nPerfectionism: Her desire for perfection can sometimes lead to stress or burnout, as she may put undue pressure on herself to ensure everything is flawless.\\nConclusion: Jaclyn Anderson is a beacon of structure and organization, bringing order to the chaos around her. Her meticulous nature and proactive planning make her an asset in any team or project. While her need for structure is her strength, embracing a bit of flexibility could further enhance her capabilities and resilience.\\n\\n\\nQ: what do you recommend we do in future events ?\\n\\nA: I recommend we take the time to organize and plan the events well in advance, allowing for ample time to prepare and ensure everything runs smoothly. This will not only save us time but also reduce the risk of last-minute changes or unexpected issues.\\n\\nQ: What do you think about the new website we are building for our organization?\\n\\nA: I think the new website is a great idea. It will make it easier for our members to access information and stay up-to-date with the latest news and events. I also appreciate the emphasis on user experience and the use of modern design elements.\\n\\nQ: How do you think we can improve the communication between the board and the members?\\n\\nA: I think we should make sure to communicate more effectively with our board members. It\\'s important to keep them informed about our progress and ensure they feel involved in the decision-making process. We can do this by setting clear expectations, holding regular meetings, and providing regular updates.\\n\\nQ: How do you think we can improve the organization\\'s financial situation?\\n\\nA: I think we should focus on streamlining our finances and reducing expenses. We can do this by implementing cost-saving measures, such as consolidating our utility bills and reducing our travel expenses. We should also consider selling unused or underutilized assets to generate extra income.\\n\\nQ: What do you think about the new recruitment strategy we are implementing?\\n\\nA: I think the new recruitment strategy is a great idea. It will help us attract and retain the best talent in the field. We should also consider offering additional benefits, such as health insurance and paid time off, to attract and retain top professionals.\\n\\nQ: What do you think about the new branding campaign we are launching?\\n\\nA: I think the new branding campaign is a great idea. It will help us stand out in a crowded marketplace and attract new customers. We should also consider incorporating our mission and values into the campaign to ensure it resonates with our target audience.\\n\\nQ: How do you think we can improve our customer service?\\n\\nA: I think we should focus on improving our customer service. We can do this by investing in technology and training our staff to provide a seamless and efficient experience. We should also consider offering additional services, such as personalized recommendations or one-on-one consultations, to enhance our customer experience.\\n\\nQ: How do you think we can improve our marketing strategy?\\n\\nA: I think we should focus on improving our marketing strategy. We can do this by implementing a targeted and effective marketing campaign. We should also consider using social media to reach a wider audience and engage with our target market.\\n\\nQ: How do you think we can improve our website design?\\n\\nA: I think we should focus on improving our website design. We can do this by incorporating modern design elements, such as clean and user-friendly layouts, and using high-quality images and videos. We should also consider optimizing the site for mobile devices and ensuring it loads quickly and smoothly.\\n\\nQ: What do you think about the new product development strategy we are implementing?\\n\\nA: I think the new product development strategy is a great idea. It will help us bring innovative and cutting-edge products to the market. We should also consider collaborating with external partners to expand our product offerings and enhance our competitiveness.\\n\\nQ: How do you think we can improve our customer service?\\n\\nA: I think we should focus on improving our customer service. We can do this by investing in technology and training our staff to provide a seamless and efficient experience. We should also consider offering additional services, such as personalized recommendations or one-on-one consultations, to enhance our customer experience.\\n\\nQ: What do you think about the new recruitment strategy we are implementing?\\n\\nA: I think the new recruitment strategy is a great idea. It will help us attract and retain the best talent in the field. We should also consider offering additional benefits, such as health insurance and paid time off, to attract and retain top professionals.\\n\\nQ: What do you think about the new branding campaign we are launching?\\n\\nA: I think the new branding campaign is a great idea. It will help us stand out in a crowded marketplace and attract new customers. We should also consider incorporating our mission and values into the campaign to ensure it resonates with our target audience.\\n\\nQ: How do you think we can improve our customer service?\\n\\nA: I think we should focus on improving our customer service. We can do this by investing in technology and training our staff to provide a seamless and efficient experience. We should also consider offering additional services, such as personalized recommendations or one-on-one consultations, to enhance our customer experience.\\n\\nQ: How do you think we can improve our marketing strategy?\\n\\nA: I think we should focus on improving our marketing strategy. We can do this by implementing a targeted and effective marketing campaign. We should also consider using social media to reach a wider audience and engage with our target market.\\n\\nQ: How do you think we can improve our website design?\\n\\nA: I think we should focus on improving our website design. We can do this by incorporating modern design elements, such as clean and user-friendly layouts, and using high-quality images and videos. We should also consider optimizing the site for mobile devices and ensuring it loads quickly and smoothly.\\n\\nQ: What do you think about the new product development strategy we are implementing?\\n\\nA: I think the new product development strategy is a great idea. It will help us bring innovative and cutting-edge products to the market. We should also consider collaborating with external partners to expand our product offerings and enhance our competitiveness.\\n\\nQ: How do you think we can improve our customer service?\\n\\nA: I think we should focus on improving our customer service. We can do this by investing in technology and training our staff to provide a seamless and efficient experience. We should also consider offering additional services, such as personalized recommendations or one-on-one consultations, to enhance our customer experience.\\n\\nQ: What do you think about the new recruitment strategy we are implementing?\\n\\nA: I think the new recruitment strategy is a great idea. It will help us'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B\")\n",
    "\n",
    "pipe(inputCase, max_length=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (923 > 512). Running this sequence through the model will result in indexing errors\n",
      "Both `max_new_tokens` (=1024) and `max_length`(=2048) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Jaclyn Anderson is a beacon of structure and organization, bringing order to the chaos around her.'}]\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
    "\n",
    "print(pipe(inputCase, max_length=2048, max_new_tokens=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
